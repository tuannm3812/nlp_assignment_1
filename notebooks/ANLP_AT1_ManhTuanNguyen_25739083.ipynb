{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AhFOUj6iCWG"
      },
      "source": [
        "# Natural Language Processing of Parlimentary Data For Understanding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upt31tR9Dnv7"
      },
      "source": [
        "# Table of Contents\n",
        "- [1. Introduction](#1-introduction)\n",
        "- [2. Data Loading and Inspection](#2-data-loading)\n",
        "- [3. Data Cleaning and Preparation](#3-data-cleaning)\n",
        "- [4. Exploratory Data Analysis (EDA)](#4-eda)\n",
        "- [5. Detailed Investigation of Key Trends](#5-detailed-investigation)\n",
        "- [6. Insights and Recommendations](#6-insights)\n",
        "- [7. Limitations and Next Steps](#7-limitations)\n",
        "- [8. Conclusion](#8-conclusion)\n",
        "- [9. References](#9-references)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3u5Fl1vDnv7"
      },
      "source": [
        "# 1. Introduction <a id=\"1-introduction\"></a>\n",
        "\n",
        "## 1.1 Policy Context: From Reporting to Action\n",
        "Australia’s **Workplace Gender Equality Amendment (Setting Gender Equality Targets) Bill 2024** marks a pivotal shift in the nation's approach to closing the gender pay gap. Moving beyond the existing framework of voluntary reporting, the Bill introduces a requirement for **\"Designated Relevant Employers\" (DREs)**—those with 500 or more employees—to proactively select and meet measurable gender equality targets over a rolling **three-year cycle**.\n",
        "\n",
        "This legislation is designed to bridge the \"action gap,\" ensuring that large organisations do not just measure inequality but actively dismantle it.\n",
        "\n",
        "## 1.2 The Data Source: Parliamentary Inquiry\n",
        "In parallel with the legislative process, the **Senate Finance and Public Administration Legislation Committee** conducted a formal inquiry into the Bill. This inquiry invited public comment to gather evidence on the feasibility, impact, and design of the proposed targets.\n",
        "\n",
        "<img src=\"https://www.aph.gov.au/-/media/02_Parliamentary_Business/24_Committees/243_Reps_Committees/Info/images/Inquiry_process.jpg\" alt=\"Parliamentary Inquiry Process\" width=\"800\"/>\n",
        "\n",
        "*Figure 1.1: The Parliamentary Committee Inquiry Process. This analysis focuses on the \"Evidence gathering\" phase.*\n",
        "\n",
        "The dataset for this analysis consists of the **31 written submissions** received during the inquiry. These documents are not merely opinions; they are strategic arguments crafted by **Unions**, **Industry Bodies**, **Advocacy Groups**, and **Government Agencies**. They reveal how different sectors anticipate the benefits, risks, and administrative burdens of the new regime.\n",
        "\n",
        "## 1.3 Research Objectives\n",
        "This project applies Natural Language Processing (NLP) techniques to deconstruct the discourse surrounding the Bill. The analysis is guided by the overarching question:\n",
        "\n",
        "> **How do different stakeholders frame the shift from voluntary reporting to mandatory targets, and what linguistic patterns reveal their underlying priorities?**\n",
        "\n",
        "To answer this, we investigate three specific sub-questions:\n",
        "\n",
        "1.  **Thematic Divergence:** What are the dominant latent topics in the corpus (e.g., *compliance mechanics* vs. *workplace safety*) and how does their prevalence vary between Industry and Union stakeholders?\n",
        "2.  **Stance & Vocabulary:** How do **supportive** vs. **cautious** submissions differ in their lexical choices? Do they speak the same language, or are they focusing on fundamentally different aspects of the Bill?\n",
        "3.  **Policy Granularity:** To what extent does the debate focus on high-level ideology versus specific implementation details (e.g., *baseline years*, *numeric vs. action targets*, and *enforcement*)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZNob1koDnv8"
      },
      "source": [
        "## Setup packages and file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsiuqZxYDnv8",
        "outputId": "95083351-8925-447e-9ea4-982aec1ce269",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "'apt-get' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install pdfplumber --quiet\n",
        "!pip install pdfplumber pytesseract pdf2image pillow --quiet\n",
        "!apt-get install poppler-utils -y\n",
        "!pip install gensim --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2BPyeM5KDnv9",
        "outputId": "9e3a26ae-f5ba-4bf9-c467-5edd4c854070"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\ThinkPad\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\ThinkPad\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\ThinkPad\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All core libraries and packages imported.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import string\n",
        "import itertools\n",
        "from collections import Counter\n",
        "from typing import Any, Dict, List, Tuple # New: Added typing module\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# NLTK imports and downloads\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.util import ngrams # New: Added ngrams for global access\n",
        "\n",
        "# PDF/OCR imports\n",
        "import pdfplumber\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "\n",
        "# Gensim imports\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import LdaModel\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "\n",
        "# Scikit-learn imports\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Other imports\n",
        "import networkx as nx # New: Added networkx for global access\n",
        "from wordcloud import WordCloud\n",
        "from tqdm.notebook import tqdm # New: Added tqdm for progress bars\n",
        "\n",
        "# DataFrame display options\n",
        "pd.set_option(\"display.max_colwidth\", 150)\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "print(\"All core libraries and packages imported.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t4Q6HVtDnv9"
      },
      "source": [
        "# 2. Data Loading and Inspection <a id=\"2-data-loading\"></a>\n",
        "\n",
        "To transform the unstructured PDF submissions into an analysis-ready dataset, a hybrid extraction pipeline was implemented:\n",
        "\n",
        "1.  **Text Extraction Strategy:** The `pdfplumber` library is used for digital-native documents to ensure high-fidelity text retrieval. A fallback mechanism using **Optical Character Recognition (OCR)** (via `pytesseract`) is triggered automatically for scanned image-based PDFs (e.g., older scanned letters).\n",
        "2.  **Metadata Parsing:** Submitter names are parsed directly from filenames. A custom classification logic maps these names to distinct **Stakeholder Groups** (e.g., *Union/Worker Rep*, *Industry/Employer Body*, *Government*) to enable comparative analysis in later sections.\n",
        "3.  **Data Cleaning:** Preliminary cleaning functions are applied during loading to resolve common PDF artifacts, such as hyphenated line breaks and specific character encoding errors found in bolded headers (e.g., repairing broken text in the ACTU submission)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQf9xGqvu0sd",
        "outputId": "cc03bb90-ad82-450e-8815-a625e42a752b"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "84097da37bee40bbbee365f8248afb62",
            "02c8f198976d49a4824ba1f943769023",
            "e0eba986aedd4869a2cd8b652a376175",
            "e7ec44fe4a364f348a419cf0c0e0e072",
            "b7bd15568ef64f4cabe5efbc644674ab",
            "6083d51d358e4f9caaff7eb39de3cc80",
            "b75957f7077f47eb985b806d2ab55d90",
            "c85ccbd6df534ee58726b2af81edb591",
            "e5d869c5c6924118bbbd10088d4fd21e",
            "eeb4c46149d34fe38e6059b4bf81bf09",
            "cfa352a2031143d0a00b5ce268b7b03c"
          ]
        },
        "id": "n_VZb02uDnv-",
        "outputId": "d69ec4d8-6b8d-4a12-8bc8-dd5a171c6c56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: Directory not found at ./data/raw/submissions_genderequity bill\n",
            "Please ensure Google Drive is mounted.\n"
          ]
        }
      ],
      "source": [
        "# 2. Data Loading and Initial Inspection - Pre-Processing\n",
        "# --- Configuration & Constants ---\n",
        "# DATA_PATH = (\n",
        "#     \"/content/drive/MyDrive/Sem3_2026 Autumn/\"\n",
        "#     \"36118 Applied Natural Language Processing/nlp_assignments/nlp_AT1/\"\n",
        "#     \"submissions_genderequity bill\"\n",
        "# )\n",
        "DATA_PATH = './data/submissions_genderequity bill'  # Local path for testing\n",
        "OCR_WORD_THRESHOLD = 150  # Fallback to OCR if extracted words are fewer than this\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def fix_double_encoding(text: str) -> str:\n",
        "    \"\"\"Fixes specific bolding artifacts found in ACTU submission headers.\"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "\n",
        "    # Map of garbled text found in the logs -> Correct text\n",
        "    corrections = {\n",
        "        r\"WWoorrkkppllaaccee\": \"Workplace\",\n",
        "        r\"GGeennddeerr\": \"Gender\",\n",
        "        r\"EEqquuaalliittyy\": \"Equality\",\n",
        "        r\"AAmmeennddmmeenntt\": \"Amendment\",\n",
        "        r\"SSeettttiinngg\": \"Setting\",\n",
        "        r\"TTaarrggeettss\": \"Targets\",\n",
        "        r\"BBiillll\": \"Bill\",\n",
        "        r\"SSuubbmmiissssiioonn\": \"Submission\"\n",
        "    }\n",
        "\n",
        "    for pattern, replacement in corrections.items():\n",
        "        text = re.sub(pattern, replacement, text)\n",
        "\n",
        "    return text\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    \"\"\"Standardizes text by fixing hyphenation, whitespace, and artifacts.\"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "\n",
        "    # 1. Fix the specific PDF doubling artifact found in ACTU submission\n",
        "    text = fix_double_encoding(text)\n",
        "\n",
        "    # 2. Fix words broken by hyphens across lines (e.g., \"govern-\\nment\")\n",
        "    text = re.sub(r\"(\\w+)-\\s*\\n\\s*(\\w+)\", r\"\\1\\2\", text)\n",
        "\n",
        "    # 3. Normalize whitespace (replace multiple newlines/tabs with single space)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "\n",
        "    # 4. Filter non-printable chars\n",
        "    text = \"\".join(filter(lambda x: x in string.printable, text))\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "def parse_filename(filename: str) -> Tuple[int, str]:\n",
        "    \"\"\"Extracts submission ID and submitter name from the filename.\n",
        "\n",
        "    Behaviour:\n",
        "    - Prefer explicit numeric prefix like \"12. Submitter Name.pdf\".\n",
        "    - Otherwise, fall back to the first number found anywhere in the filename.\n",
        "    - If no number is found, return -1 and the cleaned name.\n",
        "    \"\"\"\n",
        "    name_clean = re.sub(r\"\\.pdf$\", \"\", filename, flags=re.IGNORECASE).strip()\n",
        "\n",
        "    # 1) Explicit prefix: '12. Name'\n",
        "    m = re.search(r\"^(\\d+)\\.\\s*(.*)\", name_clean)\n",
        "    if m:\n",
        "        return int(m.group(1)), m.group(2).strip()\n",
        "\n",
        "    # 2) Any number in the filename (fallback)\n",
        "    m2 = re.search(r\"(\\d+)\", name_clean)\n",
        "    if m2:\n",
        "        return int(m2.group(1)), name_clean\n",
        "\n",
        "    # 3) No numeric identifier found\n",
        "    return -1, name_clean\n",
        "\n",
        "def categorize_stakeholder(name: str) -> str:\n",
        "    \"\"\"Classifies submitter into policy-relevant stakeholder groups.\"\"\"\n",
        "    name_lower = name.lower()\n",
        "\n",
        "    # 1. Government / Statutory\n",
        "    if any(k in name_lower for k in [\n",
        "        \"workplace gender equality agency\", \"wgea\",\n",
        "        \"human rights commission\", \"public service commission\",\n",
        "        \"gender equality in the public sector\"\n",
        "    ]):\n",
        "        return \"Government/Statutory\"\n",
        "\n",
        "    # 2. Unions & Worker Reps\n",
        "    if any(k in name_lower for k in [\n",
        "        \"union\", \"actu\", \"trades hall\", \"anmf\", \"cpsu\", \"aeu\",\n",
        "        \"queensland council\"\n",
        "    ]):\n",
        "        return \"Union/Worker Rep\"\n",
        "\n",
        "    # 3. Industry/Employer Bodies\n",
        "    # Includes specific peak bodies and associations\n",
        "    if any(k in name_lower for k in [\n",
        "        \"minerals council\", \"retailers association\", \"industry group\",\n",
        "        \"clubs australia\", \"master electricians\", \"business council\",\n",
        "        \"financial markets association\", \"chief executive women\",\n",
        "        \"chief exectuive\", \"law council\"\n",
        "    ]):\n",
        "        return \"Industry/Employer Body\"\n",
        "\n",
        "    # 4. Investors / Finance\n",
        "    if any(k in name_lower for k in [\"superannuation\", \"acsi\", \"investor\"]):\n",
        "        return \"Investor/Finance\"\n",
        "\n",
        "    # 5. Advocacy / NGO\n",
        "    if any(k in name_lower for k in [\n",
        "        \"diversity council\", \"sage\", \"science in australia\",\n",
        "        \"migrant workers\", \"gender equality and leadership\"\n",
        "    ]):\n",
        "        return \"Advocacy/NGO\"\n",
        "\n",
        "    # 6. Corporate\n",
        "    if any(k in name_lower for k in [\"virgin australia\"]):\n",
        "        return \"Corporate\"\n",
        "\n",
        "    # 7. Academic / Individual\n",
        "    if any(k in name_lower for k in [\"dr \", \"mr \", \"name withheld\", \"mchri\"]):\n",
        "        return \"Academic/Individual\"\n",
        "\n",
        "    return \"Other\"\n",
        "\n",
        "def extract_pdf_content(pdf_path: str) -> str:\n",
        "    \"\"\"Extracts text from a PDF, falling back to OCR if necessary.\"\"\"\n",
        "    extracted_text = \"\"\n",
        "\n",
        "    # 1. Attempt standard text extraction\n",
        "    try:\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            pages_text = [p.extract_text() or \"\" for p in pdf.pages]\n",
        "            extracted_text = \"\".join(pages_text)\n",
        "    except Exception as e:\n",
        "        print(f\"pdfplumber error on {os.path.basename(pdf_path)}: {e}\")\n",
        "\n",
        "    # 2. Fallback to OCR if text is insufficient\n",
        "    if len(extracted_text.split()) < OCR_WORD_THRESHOLD:\n",
        "        print(f\"OCR activated for: {os.path.basename(pdf_path)}\")\n",
        "        try:\n",
        "            pages = convert_from_path(pdf_path)\n",
        "            ocr_text = [pytesseract.image_to_string(img) for img in pages]\n",
        "            extracted_text = \"\".join(ocr_text)\n",
        "        except Exception as e:\n",
        "            print(f\"OCR error on {os.path.basename(pdf_path)}: {e}\")\n",
        "\n",
        "    return extracted_text\n",
        "\n",
        "def load_submission_data(source_dir: str) -> pd.DataFrame:\n",
        "    \"\"\"Iterates through PDFs in a directory and compiles a DataFrame.\"\"\"\n",
        "    records = []\n",
        "\n",
        "    # Filter for PDF files only\n",
        "    pdf_files = sorted(\n",
        "        [f for f in os.listdir(source_dir) if f.lower().endswith(\".pdf\")]\n",
        "    )\n",
        "\n",
        "    print(f\"Found {len(pdf_files)} files. Beginning extraction...\")\n",
        "\n",
        "    for filename in tqdm(pdf_files, desc=\"Processing Submissions\"):\n",
        "        file_path = os.path.join(source_dir, filename)\n",
        "\n",
        "        # Extraction & Cleaning\n",
        "        raw_text = extract_pdf_content(file_path)\n",
        "        clean_content = clean_text(raw_text)\n",
        "\n",
        "        # Metadata Parsing\n",
        "        sub_id, sub_name = parse_filename(filename)\n",
        "        stakeholder_type = categorize_stakeholder(sub_name)\n",
        "\n",
        "        records.append({\n",
        "            \"submission_id\": sub_id,\n",
        "            \"submitter_name\": sub_name,\n",
        "            \"stakeholder_type\": stakeholder_type,\n",
        "            \"filename\": filename,\n",
        "            \"clean_text\": clean_content,\n",
        "            \"raw_text\": raw_text,\n",
        "            \"char_count\": len(clean_content),\n",
        "            \"word_count\": len(clean_content.split()),\n",
        "        })\n",
        "\n",
        "    # Create DataFrame and sort\n",
        "    submissions_df = pd.DataFrame(records)\n",
        "    submissions_df = submissions_df.sort_values(\"submission_id\").reset_index(\n",
        "        drop=True\n",
        "    )\n",
        "\n",
        "    return submissions_df\n",
        "\n",
        "def plot_corpus_stats(df: pd.DataFrame) -> None:\n",
        "    \"\"\"Visualizes basic statistics of the loaded corpus.\"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "    # Plot 1: Stakeholder Distribution\n",
        "    sns.countplot(\n",
        "        y=\"stakeholder_type\",\n",
        "        data=df,\n",
        "        order=df[\"stakeholder_type\"].value_counts().index,\n",
        "        ax=axes[0],\n",
        "        palette=\"viridis\",\n",
        "        hue=\"stakeholder_type\",\n",
        "        legend=False\n",
        "    )\n",
        "    axes[0].set_title(\"Count of Submissions by Stakeholder Type\")\n",
        "    axes[0].set_xlabel(\"Count\")\n",
        "    axes[0].set_ylabel(\"Stakeholder Type\")\n",
        "\n",
        "    # Plot 2: Word Count Distribution\n",
        "    sns.histplot(df[\"word_count\"], bins=15, kde=True, ax=axes[1], color=\"teal\")\n",
        "    axes[1].set_title(\"Distribution of Submission Lengths (Word Count)\")\n",
        "    axes[1].set_xlabel(\"Number of Words\")\n",
        "    axes[1].set_ylabel(\"Frequency\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# --- Execution Logic ---\n",
        "\n",
        "# Check if path exists (prevents crashing if Drive isn't mounted)\n",
        "if os.path.exists(DATA_PATH):\n",
        "    # 1. Load Data\n",
        "    submissions_df = load_submission_data(DATA_PATH)\n",
        "\n",
        "    # 2. Print Summary Stats\n",
        "    print(\"\\n--- Data Loading Complete ---\")\n",
        "    print(f\"Total Submissions: {len(submissions_df)}\")\n",
        "    print(\"Stakeholder Breakdown:\")\n",
        "    print(submissions_df[\"stakeholder_type\"].value_counts())\n",
        "\n",
        "    # 3. Visualize\n",
        "    plot_corpus_stats(submissions_df)\n",
        "\n",
        "    # 4. Show DataFrame\n",
        "    display(submissions_df.head(10))\n",
        "\n",
        "    # 5. Technical Inspection\n",
        "    print(\"\\n--- Technical Inspection ---\")\n",
        "    submissions_df.info()\n",
        "    print(\"\\n--- Unclassified Stakeholders (Should be Empty) ---\")\n",
        "    display(submissions_df[submissions_df[\"stakeholder_type\"] == \"Other\"][[\"filename\", \"submitter_name\"]])\n",
        "\n",
        "else:\n",
        "    print(f\"Error: Directory not found at {DATA_PATH}\")\n",
        "    print(\"Please ensure Google Drive is mounted.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNNYx-ymUlGk",
        "outputId": "d668b042-ec6c-4292-f25a-e1f00b74d789"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 1000 characters of each submission's text:\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'submissions_df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Display the first 1000 characters of each submission's raw text\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFirst 1000 characters of each submission\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms text:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43msubmissions_df\u001b[49m.iterrows():\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Submission: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[33m'\u001b[39m\u001b[33mfilename\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(row[\u001b[33m'\u001b[39m\u001b[33mclean_text\u001b[39m\u001b[33m'\u001b[39m][:\u001b[32m1000\u001b[39m])\n",
            "\u001b[31mNameError\u001b[39m: name 'submissions_df' is not defined"
          ]
        }
      ],
      "source": [
        "# Display the first 1000 characters of each submission's raw text\n",
        "print(\"First 1000 characters of each submission's text:\")\n",
        "for index, row in submissions_df.iterrows():\n",
        "    print(f\"\\n--- Submission: {row['filename']} ---\")\n",
        "    print(row['clean_text'][:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f67de5f1"
      },
      "source": [
        "## Key Observations from Initial Inspection\n",
        "\n",
        "The extraction process successfully retrieved text from all **31 submissions**, resulting in a complete dataset for analysis.\n",
        "\n",
        "**1. Stakeholder Landscape: A Polarized Debate**\n",
        "The classification reveals a striking balance in the consultation process. The two dominant voices are **Union/Worker Representatives** (9 submissions) and **Industry/Employer Bodies** (9 submissions), collectively comprising nearly **60%** of the corpus.\n",
        "* *Implication:* This suggests the inquiry is fundamentally a negotiation between two opposing forces: those advocating for stronger compliance/worker rights and those concerned with regulatory burden and implementation costs.\n",
        "\n",
        "**2. Data Quality & OCR**\n",
        "* **Scanned Documents:** Three submissions—*Australian Retailers Association*, *Virgin Australia*, and *Minerals Council of Australia*—were identified as image-based PDFs. The OCR pipeline successfully transcribed these, ensuring the views of major industry players are included.\n",
        "* **Artifact Removal:** Inspection confirms that previous character-doubling artifacts (e.g., in the ACTU header) have been successfully normalized.\n",
        "\n",
        "**3. Document Complexity (Word Counts)**\n",
        "* **High Variance:** Submission lengths vary drastically, from a brief **221 words** (likely a simple cover letter) to a massive **14,064 words** (comprehensive policy reports).\n",
        "* **Distribution:** The data is strongly right-skewed (Mean: ~2,500 words).\n",
        "* *Analytical Note:* Simple frequency counts will be naturally biased toward the 3–4 longest documents. Subsequent analysis (Topic Modelling) will utilize **TF-IDF normalization** to prevent these long documents from drowning out shorter, equally valid submissions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxxChwaTDnv-"
      },
      "source": [
        "# 3. Data Cleaning and Preparation  <a id=\"3-data-cleaning\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tKuy5RDbDnv-",
        "outputId": "65c23c2d-a1e6-4661-83e5-b93aca50118a"
      },
      "outputs": [],
      "source": [
        "# Setup & Optimized Stopwords\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# --- 1. Setup Resources ---\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "# --- 2. Define Stopwords ---\n",
        "# Base English stopwords\n",
        "base_stopwords = set(stopwords.words('english'))\n",
        "\n",
        "# Domain-specific stopwords (Parliamentary/Formal procedural terms)\n",
        "# We remove specific numbers from this list because we will handle ALL numbers via regex\n",
        "domain_stopwords = {\n",
        "    \"bill\", \"workplace\", \"gender\", \"equality\", \"targets\", \"amendment\",\n",
        "    \"submission\", \"submissions\", \"inquiry\", \"act\", \"wgea\", \"agency\",\n",
        "    \"australia\", \"australian\", \"commonwealth\", \"government\",\n",
        "    \"senate\", \"committee\", \"parliament\", \"chair\", \"senator\",\n",
        "    \"finance\", \"public\", \"administration\", \"house\", \"re\",\n",
        "    \"page\", \"figure\", \"table\", \"para\", \"attachment\", \"appendix\",\n",
        "    \"pdf\", \"www\", \"gov\", \"govau\", \"http\", \"https\",\n",
        "    \"also\", \"would\", \"could\", \"should\", \"may\", \"must\", # Modal verbs\n",
        "    \"redneg\", \"ytilauqe\", # OCR artifacts (reversed words)\n",
        "}\n",
        "\n",
        "# Combine sets\n",
        "final_stopwords = base_stopwords.union(domain_stopwords)\n",
        "\n",
        "print(f\"Total distinct stopwords defined: {len(final_stopwords)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hqv8sBVTDnv-"
      },
      "outputs": [],
      "source": [
        "# Optimized TextPreprocessor Class\n",
        "class TextPreprocessor:\n",
        "    \"\"\"\n",
        "    A modular text preprocessor for parliamentary submissions.\n",
        "    \"\"\"\n",
        "    def __init__(self, stop_words: set, stem: bool = False):\n",
        "        self.stop_words = stop_words\n",
        "        self.stem = stem\n",
        "        self.stemmer = PorterStemmer() if stem else None\n",
        "\n",
        "        # Pre-compile regex for efficiency\n",
        "        self.space_after_paren = re.compile(r'\\)')\n",
        "        self.extra_whitespace = re.compile(r'\\s+')\n",
        "\n",
        "        # Create a translation table for fast punctuation removal\n",
        "        # We keep hyphens (-) to preserve compound words like 'decision-making' initially\n",
        "        remove_chars = string.punctuation.replace('-', '') + \"–—’“”\"\n",
        "        self.translator = str.maketrans('', '', remove_chars)\n",
        "\n",
        "    def preprocess(self, text: str) -> str:\n",
        "        if not isinstance(text, str) or not text:\n",
        "            return \"\"\n",
        "\n",
        "        # 1. Structural cleaning (Regex & String Ops)\n",
        "        # Fix \"word)\" -> \"word) \"\n",
        "        text = self.space_after_paren.sub(') ', text)\n",
        "        # Lowercase\n",
        "        text = text.lower()\n",
        "        # Remove punctuation using fast C-level translation\n",
        "        text = text.translate(self.translator)\n",
        "        # Remove numbers (replace digits with space)\n",
        "        text = re.sub(r'\\d+', ' ', text)\n",
        "\n",
        "        # 2. Tokenization (Do this ONCE)\n",
        "        tokens = word_tokenize(text)\n",
        "\n",
        "        # 3. Filtering & Stemming Loop\n",
        "        cleaned_tokens = []\n",
        "        for tok in tokens:\n",
        "            # Remove short tokens (e.g., 'ab', '1') and stopwords\n",
        "            if len(tok) > 2 and tok not in self.stop_words:\n",
        "                # Remove hyphens at edges (\"-the\") but keep compounds (\"co-design\")\n",
        "                tok = tok.strip('-')\n",
        "\n",
        "                if self.stem:\n",
        "                    cleaned_tokens.append(self.stemmer.stem(tok))\n",
        "                else:\n",
        "                    cleaned_tokens.append(tok)\n",
        "\n",
        "        # 4. Rejoin\n",
        "        return \" \".join(cleaned_tokens)\n",
        "\n",
        "# --- Initialize Preprocessors ---\n",
        "# 1. For Human Readability (Topics / Word Clouds)\n",
        "processor_no_stem = TextPreprocessor(stop_words=final_stopwords, stem=False)\n",
        "\n",
        "# 2. For Algorithmic Weighting (TF-IDF / Clustering)\n",
        "processor_stemmed = TextPreprocessor(stop_words=final_stopwords, stem=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514,
          "referenced_widgets": [
            "8071c0c04d8342a4b68b7827c16034f3",
            "8ec67aea01d547008cf2b0209554154b",
            "2f123b12c83b48e184bac34507dc38bf",
            "52d227c31d224163b660d77bfdb78c05",
            "4408f0ce670240efb7e6023e227c86e3",
            "57543cd80a7749888f3ed98be797446c",
            "8377408e7f99409a8ea5820f46293a62",
            "875fe2fde32f4cbe995edd5ef4b8e60b",
            "dae63b77cba545e28e8014dcad0e3c28",
            "77f78597e4bb42728e30c9e8eadec271",
            "19a4054507a040f9b32fd3bde5c3913c",
            "5933ae41cb614ed7811738a597e0e4d5",
            "a5b3f681155d4b16b599f0c8b4ce2ca3",
            "2beeba74bd8048869fc161b6df2cdf19",
            "ac9b308419cf4208a95815fa50e6e956",
            "632a6570f79f41e7aa8a7d9aa21c6db2",
            "714101333be0494286303e138c5c5e37",
            "0216609e7ecb4702b29fc8d6052b7bc4",
            "d900f7001010483fb76a6c5c612a2c36",
            "2027e22ebcb5426fb03d97463dc373df",
            "436311c4cc504ed0b75d9e9c60e16979",
            "8f76c307fa7c4272bb70c687323dcb91"
          ]
        },
        "collapsed": true,
        "id": "l17X0ZTcDnv-",
        "outputId": "f6bb1629-1c2b-4b67-95d4-a265b759f724"
      },
      "outputs": [],
      "source": [
        "# Apply cleaning\n",
        "# Note: We use the 'clean_text' from the previous section as input\n",
        "tqdm.pandas(desc=\"Cleaning (No Stem)\")\n",
        "submissions_df['processed_text'] = submissions_df['clean_text'].progress_apply(processor_no_stem.preprocess)\n",
        "\n",
        "tqdm.pandas(desc=\"Cleaning (Stemmed)\")\n",
        "submissions_df['stemmed_text'] = submissions_df['clean_text'].progress_apply(processor_stemmed.preprocess)\n",
        "\n",
        "# Create token lists (split on whitespace is safe now after preprocessing)\n",
        "submissions_df['tokens'] = submissions_df['processed_text'].str.split()\n",
        "\n",
        "# Calculate new word counts\n",
        "submissions_df['n_words_processed'] = submissions_df['tokens'].apply(len)\n",
        "\n",
        "# --- Display Results ---\n",
        "print(\"\\n--- Cleaning Impact Summary ---\")\n",
        "print(f\"Original Word Count (Total): {submissions_df['word_count'].sum():,}\")\n",
        "print(f\"Processed Word Count (Total): {submissions_df['n_words_processed'].sum():,}\")\n",
        "reduction = 100 * (1 - submissions_df['n_words_processed'].sum() / submissions_df['word_count'].sum())\n",
        "print(f\"Data Reduction: {reduction:.1f}% noise removed\")\n",
        "\n",
        "display(submissions_df[['submitter_name', 'word_count', 'n_words_processed']].head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "collapsed": true,
        "id": "jnhzueAtDnv_",
        "outputId": "9b14d913-af20-477d-c3a9-01fd884adee6"
      },
      "outputs": [],
      "source": [
        "# Compare Original vs Processed lengths\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot Original\n",
        "sns.kdeplot(\n",
        "    submissions_df['word_count'],\n",
        "    color='teal',\n",
        "    fill=True,\n",
        "    label='Original Text',\n",
        "    clip=(0, None)\n",
        ")\n",
        "\n",
        "# Plot Processed\n",
        "sns.kdeplot(\n",
        "    submissions_df['n_words_processed'],\n",
        "    color='purple',\n",
        "    fill=True,\n",
        "    label='Cleaned Text (No Stopwords)',\n",
        "    clip=(0, None)\n",
        ")\n",
        "\n",
        "plt.title('Impact of Data Cleaning on Submission Word Counts')\n",
        "plt.xlabel('Number of Words per Submission')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1675de88"
      },
      "source": [
        "## Summary of Data Cleaning and Preparation\n",
        "\n",
        "To prepare the parliamentary corpus for computational analysis, a robust preprocessing pipeline was implemented to reduce noise while preserving semantic meaning.\n",
        "\n",
        "**Approach and Methodology**\n",
        "* **Domain-Specific Filtering:** A custom stopword list was compiled to remove high-frequency procedural terms that add little analytical value (e.g., *\"submission\"*, *\"inquiry\"*, *\"senator\"*, *\"honourable\"*). Crucially, terms contained in the Bill’s title—*\"workplace\"*, *\"gender\"*, *\"equality\"*, *\"targets\"*—were also removed. This forces the analysis to uncover *underlying* themes (e.g., *\"compliance\"*, *\"parental leave\"*, *\"superannuation\"*) rather than simply identifying the topic of the legislation.\n",
        "* **Preprocessing Pipeline:** A custom `TextPreprocessor` class was developed to standardize the text through:\n",
        "    * **Normalization:** Converting all text to lowercase and handling specific punctuation artifacts (e.g., separating fused parentheses).\n",
        "    * **Noise Removal:** Efficiently stripping punctuation and numeric digits using translation tables.\n",
        "    * **Tokenization & Filtering:** Splitting text into tokens and removing those shorter than 3 characters to eliminate OCR artifacts and connective noise.\n",
        "* **Stemming:** A separate `stemmed_text` version was generated using Porter Stemming for downstream algorithmic tasks (like Clustering) where aggregating root words (e.g., *report*, *reporting*, *reported* $\\rightarrow$ *report*) is necessary.\n",
        "\n",
        "**Results and Interpretation**\n",
        "The cleaning process resulted in a significant reduction in text volume, effectively stripping away the \"bureaucratic boilerplate\" common in formal government submissions.\n",
        "\n",
        "* **Original Total Word Count:** 77,651 words\n",
        "* **Processed Word Count:** 38,057 words\n",
        "* **Data Reduction:** **51.0%** *(See Figure 3.1: Impact of Data Cleaning on Submission Word Counts)*\n",
        "\n",
        "The **51% reduction** in word count indicates that over half of the raw text in parliamentary submissions consists of structural language, formalities, and common stopwords. The KDE plot demonstrates that while the *volume* of text has decreased (shifting the distribution to the left), the *shape* of the distribution remains consistent. This confirms that the cleaning process was uniform and did not distort the relative depth of the submissions; the \"heavy\" submissions remain the most detailed, and the \"light\" submissions remain concise. The corpus is now optimized for high-quality Topic Modeling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au5muekGf19E"
      },
      "source": [
        "# 4. Exploratory Data Analysis (EDA) <a id=\"4-eda\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIyEDjs7f1yc"
      },
      "source": [
        "This section performs a comprehensive exploratory analysis of the cleaned corpus to uncover patterns, terminology, and structural differences between submissions.\n",
        "\n",
        "**Approach**\n",
        "\n",
        "We employ a multi-faceted approach to understand the dataset:\n",
        "* **Corpus-Level Statistics:** Aggregating all submissions to identify the \"global\" vocabulary of the Inquiry.\n",
        "* **N-Gram Analysis:** Extracting frequent bigrams (two-word pairs) to capture specific policy concepts (e.g., *\"parental leave\"*, *\"pay gap\"*) that single words might miss.\n",
        "* **Semantic Visualization:** Using Word Clouds and Network Graphs to visualize the strength of connections between key terms.\n",
        "* **Comparative Analysis:** Segmenting keyword frequency by `stakeholder_type` to quantify how Unions, Industry Bodies, and Government agencies prioritize different themes (e.g., *safety* vs. *compliance*).\n",
        "* **Document Embedding (PCA):** Reducing the high-dimensional text data into 2D space to visually cluster submissions by similarity.\n",
        "* **Lexical Complexity:** Calculating the Type-Token Ratio (TTR) to assess the vocabulary richness of different stakeholders.\n",
        "\n",
        "**Goals**\n",
        "\n",
        "1.  Identify the dominant substantive terms driving the debate.\n",
        "2.  Visualize the conceptual relationships between policy terms.\n",
        "3.  Determine if specific stakeholder groups use distinct lexicons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m_OP92KCf01F",
        "outputId": "ab367ca4-8411-49ee-890f-b541192b0f0f"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "from collections import Counter\n",
        "from typing import Dict, List, Tuple, Set\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from nltk.util import ngrams\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# --- Configuration ---\n",
        "PLOT_STYLE = \"whitegrid\"\n",
        "FIG_SIZE_L = (12, 6)\n",
        "FIG_SIZE_XL = (14, 10)\n",
        "TOP_N_WORDS = 20\n",
        "TOP_N_BIGRAMS = 20\n",
        "SEED = 42\n",
        "\n",
        "sns.set_style(PLOT_STYLE)\n",
        "\n",
        "# --- 1. Enhanced Stopword Configuration ---\n",
        "# We define this locally to ensure this section is self-contained\n",
        "def get_extended_stopwords() -> Set[str]:\n",
        "    \"\"\"Returns the base set plus 'setting' to refine analysis.\"\"\"\n",
        "    # Re-using the set from Section 3 but adding refinements\n",
        "    # Note: In a real notebook, you might just import 'final_stopwords' from Sec 3\n",
        "    # We redefine it here to be safe and rigorous.\n",
        "    refinements = {\"setting\", \"settings\", \"target\", \"targets\"}\n",
        "    return refinements\n",
        "\n",
        "# --- 2. Analysis Functions ---\n",
        "\n",
        "def get_corpus_stats(df: pd.DataFrame, token_col: str) -> Tuple[List[str], Counter]:\n",
        "    \"\"\"Flattens document tokens into a single corpus list and counts frequency.\"\"\"\n",
        "    # Filter out the new stopwords from the existing tokens dynamically\n",
        "    extra_stops = get_extended_stopwords()\n",
        "\n",
        "    all_tokens = [\n",
        "        token for sublist in df[token_col]\n",
        "        for token in sublist\n",
        "        if token not in extra_stops\n",
        "    ]\n",
        "    return all_tokens, Counter(all_tokens)\n",
        "\n",
        "\n",
        "def plot_top_items(\n",
        "    counter_obj: Counter,\n",
        "    n: int = 20,\n",
        "    title: str = \"Top Frequencies\",\n",
        "    color: str = \"steelblue\"\n",
        ") -> None:\n",
        "    \"\"\"Generic bar plotter for words or n-grams.\"\"\"\n",
        "    items, counts = zip(*counter_obj.most_common(n))\n",
        "\n",
        "    plt.figure(figsize=FIG_SIZE_L)\n",
        "    plt.bar(items, counts, color=color)\n",
        "    plt.title(title, fontsize=14)\n",
        "    plt.xlabel(\"Term\", fontsize=12)\n",
        "    plt.ylabel(\"Frequency\", fontsize=12)\n",
        "    plt.xticks(rotation=45, ha=\"right\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def generate_wordcloud(text_list: List[str]) -> None:\n",
        "    \"\"\"Generates and displays a word cloud from a list of tokens.\"\"\"\n",
        "    text_str = \" \".join(text_list)\n",
        "    wc = WordCloud(\n",
        "        width=1200,\n",
        "        height=600,\n",
        "        background_color=\"white\",\n",
        "        max_words=150,\n",
        "        colormap=\"viridis\",\n",
        "        random_state=SEED\n",
        "    ).generate(text_str)\n",
        "\n",
        "    plt.figure(figsize=FIG_SIZE_L)\n",
        "    plt.imshow(wc, interpolation=\"bilinear\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Corpus Word Cloud\", fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def analyze_bigrams(tokens: List[str], n: int = 20) -> Counter:\n",
        "    \"\"\"Generates bigrams and plots the network graph.\"\"\"\n",
        "    bigram_list = list(ngrams(tokens, 2))\n",
        "    bigram_counts = Counter(bigram_list)\n",
        "\n",
        "    top_bigrams = [\n",
        "        (f\"{w1} {w2}\", count) for (w1, w2), count in bigram_counts.most_common(n)\n",
        "    ]\n",
        "    plot_top_items(\n",
        "        Counter(dict(top_bigrams)),\n",
        "        n=n,\n",
        "        title=f\"Top {n} Most Common Bigrams\",\n",
        "        color=\"teal\"\n",
        "    )\n",
        "\n",
        "    return bigram_counts\n",
        "\n",
        "\n",
        "def plot_bigram_network(bigram_counts: Counter, top_k: int = 50) -> None:\n",
        "    \"\"\"Plots a network graph of the most frequent bigrams.\"\"\"\n",
        "    G = nx.Graph()\n",
        "\n",
        "    for (w1, w2), freq in bigram_counts.most_common(top_k):\n",
        "        G.add_edge(w1, w2, weight=freq)\n",
        "\n",
        "    plt.figure(figsize=FIG_SIZE_XL)\n",
        "    pos = nx.spring_layout(G, k=1.2, seed=SEED)\n",
        "\n",
        "    # Node sizing\n",
        "    node_sizes = [G.degree(n) * 150 for n in G.nodes()]\n",
        "\n",
        "    nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=\"skyblue\", alpha=0.9)\n",
        "    nx.draw_networkx_edges(G, pos, alpha=0.4, edge_color=\"gray\")\n",
        "    nx.draw_networkx_labels(G, pos, font_size=10, font_family=\"sans-serif\")\n",
        "\n",
        "    plt.title(f\"Semantic Network: Top {top_k} Bigrams\", fontsize=16)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def compare_stakeholder_themes(df: pd.DataFrame, keywords: List[str]) -> None:\n",
        "    \"\"\"Plots average keyword frequency per submission by stakeholder group.\"\"\"\n",
        "\n",
        "    # Calculate frequency of each keyword per document\n",
        "    for term in keywords:\n",
        "        df[f\"kw_{term}\"] = df[\"tokens\"].apply(\n",
        "            lambda tokens: tokens.count(term)\n",
        "        )\n",
        "\n",
        "    cols_to_agg = [f\"kw_{t}\" for t in keywords]\n",
        "    # Group and calculate mean\n",
        "    grouped = df.groupby(\"stakeholder_type\")[cols_to_agg].mean()\n",
        "\n",
        "    # Plot Heatmap\n",
        "    plt.figure(figsize=FIG_SIZE_L)\n",
        "    sns.heatmap(grouped, annot=True, cmap=\"Blues\", fmt=\".1f\", linewidths=.5)\n",
        "    plt.title(\"Average Keyword Mentions per Submission by Stakeholder\", fontsize=14)\n",
        "    plt.ylabel(\"Stakeholder Group\")\n",
        "    plt.xlabel(\"Keyword\")\n",
        "\n",
        "    # Clean up x-axis labels (remove 'kw_' prefix)\n",
        "    clean_labels = [l.replace(\"kw_\", \"\") for l in cols_to_agg]\n",
        "    plt.xticks(ticks=[i + 0.5 for i in range(len(keywords))], labels=clean_labels, rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def visualize_documents_pca(df: pd.DataFrame) -> None:\n",
        "    \"\"\"Performs TF-IDF + PCA to visualize document similarity.\"\"\"\n",
        "\n",
        "    # 1. Prepare Text\n",
        "    # We join tokens back into strings for the Vectorizer\n",
        "    docs_clean = [\" \".join(tokens) for tokens in df[\"tokens\"]]\n",
        "\n",
        "    # 2. TF-IDF Vectorization\n",
        "    tfidf = TfidfVectorizer(\n",
        "        max_features=1000,\n",
        "        ngram_range=(1, 2),\n",
        "        min_df=2 # Term must appear in at least 2 docs to be considered\n",
        "    )\n",
        "    X_tfidf = tfidf.fit_transform(docs_clean)\n",
        "\n",
        "    # 3. PCA Reduction\n",
        "    pca = PCA(n_components=2, random_state=SEED)\n",
        "    X_pca = pca.fit_transform(X_tfidf.toarray())\n",
        "\n",
        "    # 4. Plotting\n",
        "    plt.figure(figsize=FIG_SIZE_XL)\n",
        "    sns.scatterplot(\n",
        "        x=X_pca[:, 0],\n",
        "        y=X_pca[:, 1],\n",
        "        hue=df[\"stakeholder_type\"],\n",
        "        style=df[\"stakeholder_type\"],\n",
        "        s=150, # Marker size\n",
        "        palette=\"tab10\",\n",
        "        alpha=0.8\n",
        "    )\n",
        "\n",
        "    plt.title(\"Document Similarity Preview (TF-IDF + PCA)\", fontsize=16)\n",
        "    plt.xlabel(f\"PC1 (Explains {pca.explained_variance_ratio_[0]:.1%} Variance)\")\n",
        "    plt.ylabel(f\"PC2 (Explains {pca.explained_variance_ratio_[1]:.1%} Variance)\")\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def analyze_vocabulary_diversity(df: pd.DataFrame) -> None:\n",
        "    \"\"\"Calculates and visualizes Type-Token Ratio (TTR).\"\"\"\n",
        "\n",
        "    def calculate_ttr(tokens: List[str]) -> float:\n",
        "        if not tokens:\n",
        "            return 0.0\n",
        "        return len(set(tokens)) / len(tokens)\n",
        "\n",
        "    df[\"vocab_diversity\"] = df[\"tokens\"].apply(calculate_ttr)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(df[\"vocab_diversity\"], bins=10, kde=True, color=\"purple\")\n",
        "    plt.title(\"Distribution of Vocabulary Diversity (TTR)\", fontsize=14)\n",
        "    plt.xlabel(\"Type-Token Ratio (Higher = More Diverse Vocabulary)\")\n",
        "    plt.ylabel(\"Number of Submissions\")\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n--- Most Lexically Diverse Submissions ---\")\n",
        "    display(df[[\"submitter_name\", \"stakeholder_type\", \"vocab_diversity\"]]\n",
        "            .sort_values(\"vocab_diversity\", ascending=False).head(3))\n",
        "\n",
        "\n",
        "# --- Main Execution Block ---\n",
        "\n",
        "# 1. Global Corpus Stats\n",
        "print(\"--- 4.1 Global Word Frequencies ---\")\n",
        "# Using 'tokens' column from previous section\n",
        "corpus_tokens, corpus_counts = get_corpus_stats(submissions_df, \"tokens\")\n",
        "plot_top_items(corpus_counts, n=TOP_N_WORDS, title=\"Top 20 Substantive Words\")\n",
        "\n",
        "# 2. Word Cloud\n",
        "print(\"--- 4.2 Word Cloud Visualization ---\")\n",
        "generate_wordcloud(corpus_tokens)\n",
        "\n",
        "# 3. N-Gram Analysis\n",
        "print(\"--- 4.3 Bigram Analysis & Network Graph ---\")\n",
        "bigram_counts = analyze_bigrams(corpus_tokens, n=TOP_N_BIGRAMS)\n",
        "plot_bigram_network(bigram_counts, top_k=40)\n",
        "\n",
        "# 4. Stakeholder Comparative Analysis\n",
        "print(\"--- 4.4 Stakeholder Keyword Analysis ---\")\n",
        "policy_keywords = [\n",
        "    \"pay\", \"gap\", \"safety\", \"harassment\", \"data\",\n",
        "    \"compliance\", \"burden\", \"leadership\", \"leave\"\n",
        "]\n",
        "compare_stakeholder_themes(submissions_df, policy_keywords)\n",
        "\n",
        "# 5. Document Embedding (PCA)\n",
        "print(\"--- 4.5 Document Embedding (PCA) ---\")\n",
        "visualize_documents_pca(submissions_df)\n",
        "\n",
        "# 6. Vocabulary Analysis\n",
        "print(\"--- 4.6 Vocabulary Diversity Analysis ---\")\n",
        "analyze_vocabulary_diversity(submissions_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM1PNdh2DDew"
      },
      "source": [
        "## Summary of EDA Findings\n",
        "\n",
        "This section explores the thematic structure and vocabulary of the parliamentary submissions to uncover initial patterns before advanced modeling.\n",
        "\n",
        "**4.1 Dominant Themes & Terminology**\n",
        "\n",
        "The frequency analysis reveals that the discourse is anchored in practical implementation rather than abstract principles.\n",
        "* **Key Substantive Terms:** The most frequent terms—*women* (503), *employer* (393), *organisation* (180), and *data* (324)—indicate a strong focus on the **subjects of the legislation** (women) and the **agents of compliance** (employers).\n",
        "* **Workforce Focus:** The prominence of *workforce* (164) and *sector* (176) suggests that stakeholders are concerned with how these targets apply across different industries.\n",
        "*(See Figure 4.1: Top 20 Substantive Words)*\n",
        "\n",
        "**4.2 Concept Linkages (N-Grams & Networks)**\n",
        "\n",
        "The Bigram Network Graph highlights distinct conceptual clusters:\n",
        "* **The \"Economic\" Cluster:** *Pay gap* is the single most common bigram (113 counts), connecting centrally to *closing*, *gender*, and *industry*. This confirms that the \"gender pay gap\" is the primary metric of concern.\n",
        "* **The \"Safety\" Cluster:** Terms like *sexual harassment*, *violence*, and *safety* form a distinct subgraph. This indicates that stakeholders view gender equality as inextricably linked to workplace safety.\n",
        "* **The \"Compliance\" Cluster:** *Reporting obligations*, *relevant employers*, and *data collection* appear frequently together, reflecting the administrative burden on businesses.\n",
        "*(See Figure 4.3: Semantic Network)*\n",
        "\n",
        "**4.3 Stakeholder-Specific Narratives**\n",
        "\n",
        "Breaking down keyword usage by stakeholder group (Heatmap 4.4) reveals distinct priorities:\n",
        "* **Unions (e.g., HSU, ANMF):** Dominate the discussion on *pay* (mean mentions: 12.3), *leave* (12.3), and *harassment* (6.3). Their focus is clearly on worker rights and benefits.\n",
        "* **Advocacy/NGOs:** Are the primary drivers of the conversation around *data* (57.8) and *leadership* (44.5), focusing heavily on the evidence base and executive representation.\n",
        "* **Industry Bodies:** Have much lower keyword frequencies across the board (e.g., *pay*: 1.8, *data*: 1.1). This suggests they may be using different terminology, focusing perhaps on \"implementation\" or \"flexibility\" rather than the specific policy keywords tracked here.\n",
        "*(See Figure 4.4: Stakeholder Heatmap)*\n",
        "\n",
        "**4.4 Document Similarity (PCA)**\n",
        "\n",
        "The Document Embedding plot (Figure 4.5) visually confirms the divergence in stakeholder perspectives.\n",
        "* **Clustering:** \"Union/Worker Rep\" submissions (red crosses) tend to cluster in the upper-left quadrant, while \"Industry/Employer Bodies\" (purple diamonds) are dispersed more widely in the lower/right quadrants.\n",
        "* **Interpretation:** This suggests that Unions are united in their messaging (using similar vocabulary), whereas Industry bodies represent a more diverse range of sectors and concerns.\n",
        "\n",
        "**Conclusion:** The EDA confirms a \"Two Worlds\" narrative: Unions frame the Bill as a tool for **safety and fairness**, while Advocacy groups frame it as a tool for **data transparency and leadership**. Industry bodies appear to be focusing on broader, perhaps more technical, implementation details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcH1FUJ7rNV8"
      },
      "source": [
        "# 5. Detailed Investigation of Key Trends <a id=\"5-detailed-investigation\"></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FQJFc8afrNDK",
        "outputId": "6edaeed5-4faa-4f2f-9aff-c05a6715163e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import LdaModel, CoherenceModel\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "# --- Configuration ---\n",
        "NUM_TOPICS = 5\n",
        "N_CLUSTERS = 4\n",
        "RANDOM_STATE = 42\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# --- 1. LDA Topic Modeling Functions ---\n",
        "\n",
        "def train_lda_model(df: pd.DataFrame, num_topics: int) -> Tuple[LdaModel, list, Dictionary]:\n",
        "    \"\"\"Trains an LDA model on the cleaned tokens.\"\"\"\n",
        "    # Filter tokens (ensure no empty lists)\n",
        "    docs = [doc for doc in df[\"tokens\"] if len(doc) > 0]\n",
        "\n",
        "    # Create Dictionary\n",
        "    dictionary = Dictionary(docs)\n",
        "    dictionary.filter_extremes(no_below=2, no_above=0.7, keep_n=1000)\n",
        "\n",
        "    # Create Corpus\n",
        "    corpus = [dictionary.doc2bow(text) for text in docs]\n",
        "\n",
        "    # Train Model\n",
        "    lda = LdaModel(\n",
        "        corpus=corpus,\n",
        "        id2word=dictionary,\n",
        "        num_topics=num_topics,\n",
        "        random_state=RANDOM_STATE,\n",
        "        passes=20,\n",
        "        alpha='auto'\n",
        "    )\n",
        "    return lda, corpus, dictionary\n",
        "\n",
        "def assign_dominant_topics(df: pd.DataFrame, lda_model: LdaModel, corpus: list) -> pd.DataFrame:\n",
        "    \"\"\"Assigns the dominant topic and probability to each document.\"\"\"\n",
        "    dominant_topics = []\n",
        "    topic_probs = []\n",
        "\n",
        "    for bow in corpus:\n",
        "        # Get topic distribution\n",
        "        dist = lda_model.get_document_topics(bow, minimum_probability=0)\n",
        "        # Find max probability\n",
        "        sorted_dist = sorted(dist, key=lambda x: x[1], reverse=True)\n",
        "        dominant_topics.append(sorted_dist[0][0])\n",
        "        topic_probs.append(sorted_dist[0][1])\n",
        "\n",
        "    df[\"dominant_topic_id\"] = dominant_topics\n",
        "    df[\"dominant_topic_prob\"] = topic_probs\n",
        "    return df\n",
        "\n",
        "def print_topics(lda_model: LdaModel, num_topics: int):\n",
        "    \"\"\"Prints top words for each topic.\"\"\"\n",
        "    print(\"\\n--- Learned LDA Topics ---\")\n",
        "    for idx, topic in lda_model.print_topics(num_topics=num_topics, num_words=10):\n",
        "        print(f\"Topic {idx}: {topic}\")\n",
        "\n",
        "# --- 2. Clustering Functions ---\n",
        "\n",
        "def perform_clustering(df: pd.DataFrame, n_clusters: int) -> pd.DataFrame:\n",
        "    \"\"\"Performs TF-IDF Vectorization and K-Means Clustering.\"\"\"\n",
        "    # Join tokens for TF-IDF\n",
        "    docs_str = [\" \".join(t) for t in df[\"tokens\"]]\n",
        "\n",
        "    vectorizer = TfidfVectorizer(max_features=1500, min_df=2, ngram_range=(1, 2))\n",
        "    tfidf_matrix = vectorizer.fit_transform(docs_str)\n",
        "\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=RANDOM_STATE, n_init=10)\n",
        "    df[\"cluster_id\"] = kmeans.fit_predict(tfidf_matrix)\n",
        "\n",
        "    return df\n",
        "\n",
        "# --- 3. Stance Analysis Functions ---\n",
        "\n",
        "def get_stance_mapping() -> Dict[str, str]:\n",
        "    \"\"\"Returns the manual mapping of filename to stance.\"\"\"\n",
        "    return {\n",
        "        # Supportive (Unions, Advocacy, Govt, Some Industry)\n",
        "        \"1. Workplace Gender Equality Agency (WGEA).pdf\": \"Supportive\",\n",
        "        \"10. Commission for Gender Equality in the Public Sector, Victoria.PDF\": \"Supportive\",\n",
        "        \"11. Australian Council of Superannuation Investors (ACSI).PDF\": \"Supportive\",\n",
        "        \"12. Australian Nursing and Midwifery Federation (ANMF).pdf\": \"Supportive\",\n",
        "        \"14. Health Services Union (HSU).pdf\": \"Supportive\",\n",
        "        \"16. Finance Sector Union of Australia (FSU).pdf\": \"Supportive\",\n",
        "        \"18. Migrant Workers Centre (MWC)).pdf\": \"Supportive\",\n",
        "        \"19. Partnership Centre for Gender Equality and Leadership Advancement (MCHRI).PDF\": \"Supportive\",\n",
        "        \"2. Dr Leonora Risse.pdf\": \"Supportive\",\n",
        "        \"21. AEU Federal.pdf\": \"Supportive\",\n",
        "        \"22. Science in Australia Gender Equity (SAGE).pdf\": \"Supportive\",\n",
        "        \"23. Mr Greg Peak.pdf\": \"Supportive\",\n",
        "        \"25. Australian Human Rights Commission.pdf\": \"Supportive\",\n",
        "        \"26. Victorian Trades Hall Council (VTHC).pdf\": \"Supportive\",\n",
        "        \"27. Queensland Council of Unions.pdf\": \"Supportive\",\n",
        "        \"29. Unions NSW.pdf\": \"Supportive\",\n",
        "        \"3. Diversity Council Australia (DCA).pdf\": \"Supportive\",\n",
        "        \"30. Chief Exectuive Women (CEW).pdf\": \"Supportive\",\n",
        "        \"4. CPSU (PSU Group).pdf\": \"Supportive\",\n",
        "        \"7. Australian Council of Trade Unions (ACTU).pdf\": \"Supportive\",\n",
        "\n",
        "        # Cautious / Conditional (Industry Bodies)\n",
        "        \"13. Master Electricians Australia.pdf\": \"Cautious / Conditional\",\n",
        "        \"15. Clubs Australia.pdf\": \"Cautious / Conditional\",\n",
        "        \"17. Business Council of Australia (BCA).pdf\": \"Cautious / Conditional\",\n",
        "        \"20. Australian Financial Markets Association (AFMA).pdf\": \"Cautious / Conditional\",\n",
        "        \"24. Australian Retailers Association (ARA).pdf\": \"Cautious / Conditional\",\n",
        "        \"28. Virgin Australia.pdf\": \"Cautious / Conditional\",\n",
        "        \"5. Australian Industry Group.pdf\": \"Cautious / Conditional\",\n",
        "        \"6. Law Council of Australia.pdf\": \"Cautious / Conditional\",\n",
        "        \"8. Minerals Council of Australia.pdf\": \"Cautious / Conditional\", # Often supportive but with caveats on implementation\n",
        "        \"9. Australian Public Service Commission (APSC).pdf\": \"Supportive\", # Fixed mapping\n",
        "\n",
        "        # Critical / Opposed (Individual)\n",
        "        \"31. Name Withheld.pdf\": \"Critical / Opposed\",\n",
        "    }\n",
        "\n",
        "def visualize_stance_breakdown(df: pd.DataFrame, topic_labels: Dict[int, str]):\n",
        "    \"\"\"Visualizes how Stances relate to Dominant Topics with fixed formatting.\"\"\"\n",
        "    # Map labels\n",
        "    df[\"topic_label\"] = df[\"dominant_topic_id\"].map(topic_labels)\n",
        "\n",
        "    # Create Cross-tab (Row normalized)\n",
        "    ct = pd.crosstab(df[\"stance\"], df[\"topic_label\"], normalize='index')\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(12, 8)) # Increased height\n",
        "    sns.heatmap(\n",
        "        ct,\n",
        "        annot=True,\n",
        "        cmap=\"YlGnBu\",\n",
        "        fmt=\".2f\",\n",
        "        cbar_kws={'label': 'Proportion of Submissions'}\n",
        "    )\n",
        "\n",
        "    plt.title(\"Proportion of Dominant LDA Topics by Stance\", fontsize=14)\n",
        "    plt.ylabel(\"Stance\", fontsize=12)\n",
        "    plt.xlabel(\"Dominant Topic\", fontsize=12)\n",
        "\n",
        "    # ROTATE LABELS to prevent overlapping\n",
        "    plt.xticks(rotation=45, ha=\"right\")\n",
        "    plt.yticks(rotation=0) # Keep Y labels horizontal for readability\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# --- Execution ---\n",
        "\n",
        "# 1. Train LDA\n",
        "print(\"--- 5.1 Training LDA Model ---\")\n",
        "lda_model, corpus, dictionary = train_lda_model(submissions_df, NUM_TOPICS)\n",
        "print_topics(lda_model, NUM_TOPICS)\n",
        "submissions_df = assign_dominant_topics(submissions_df, lda_model, corpus)\n",
        "\n",
        "# 2. Assign Human Labels (BASED ON YOUR PREVIOUS OUTPUT - ADJUST IF NEEDED)\n",
        "# Note: LDA is random. If topics shift, update these labels based on print_topics output.\n",
        "topic_labels_map = {\n",
        "    0: \"Workplace Health, Safety & Leave\",\n",
        "    1: \"Gender Pay Gap & Equity Indicators\",\n",
        "    2: \"Legislative Scheme & Employer Duties\",\n",
        "    3: \"Business Diversity & Procurement\",\n",
        "    4: \"Data, Leadership & Evidence\"\n",
        "}\n",
        "\n",
        "# 3. Clustering\n",
        "print(\"\\n--- 5.2 Performing K-Means Clustering ---\")\n",
        "submissions_df = perform_clustering(submissions_df, N_CLUSTERS)\n",
        "\n",
        "# 4. Stance Analysis\n",
        "print(\"\\n--- 5.3 Stance Analysis ---\")\n",
        "submissions_df[\"stance\"] = submissions_df[\"filename\"].map(get_stance_mapping()).fillna(\"Mixed / Unclear\")\n",
        "visualize_stance_breakdown(submissions_df, topic_labels_map)\n",
        "\n",
        "# 5. Visualizing Clusters via PCA (Re-using columns from Sec 4 if available)\n",
        "if \"pca_x\" in submissions_df.columns:\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.scatterplot(\n",
        "        data=submissions_df, x=\"pca_x\", y=\"pca_y\",\n",
        "        hue=\"cluster_id\", style=\"stance\",\n",
        "        palette=\"deep\", s=100, alpha=0.9\n",
        "    )\n",
        "    plt.title(\"Document Clusters (Color) and Stance (Shape) in PCA Space\")\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH6WUhXRs3w7",
        "outputId": "0bf1cb38-994b-48f5-8439-c31c4562b2e1"
      },
      "outputs": [],
      "source": [
        "# Find the most representative document for each topic\n",
        "print(\"--- Representative Submissions per Topic ---\")\n",
        "for i in range(NUM_TOPICS):\n",
        "    # Find document with highest probability for this topic\n",
        "    top_doc = submissions_df[submissions_df['dominant_topic_id'] == i].sort_values('dominant_topic_prob', ascending=False).head(1)\n",
        "    if not top_doc.empty:\n",
        "        print(f\"\\nTopic {i}: {topic_labels_map.get(i, 'Unknown')}\")\n",
        "        print(f\"Top Doc: {top_doc['filename'].values[0]} (Prob: {top_doc['dominant_topic_prob'].values[0]:.2f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hhtr-GbxCsu3"
      },
      "source": [
        "## Interpretation of Trends\n",
        "\n",
        "The advanced modeling confirms that the \"gender equality\" debate is actually three distinct conversations happening in parallel:\n",
        "\n",
        "1.  **The \"Implementation\" Conversation (Topic 2):** Dominated by Industry bodies and Cautious stakeholders (67% prevalence). This discourse focuses on the mechanics of the law—*review, scheme, available, policy*. These stakeholders accept the premise but are negotiating the *process*.\n",
        "2.  **The \"Structural\" Conversation (Topic 1 & 3):** Dominated by Supportive stakeholders (38% + 14%). This discourse focuses on the *evidence* (*data, leadership*) and the *metrics* (*gap, gei*). It represents the \"technocratic\" approach to solving inequality.\n",
        "3.  **The \"Lived Experience\" Conversation (Topic 4):** This topic, characterized by words like *health, leave, violence, harassment*, bridges the gap between Supportive Unions and Individual submissions. It reframes gender equality as a matter of basic workplace safety rather than just economic statistics.\n",
        "\n",
        "**Key Finding:** The Stance Heatmap reveals a stark divide. \"Cautious\" stakeholders are almost entirely focused on **Topic 2 (Legislative Scheme)**, while \"Supportive\" stakeholders are spread across **Topics 1, 3, and 4**. This suggests that to achieve consensus, the legislation must address the *technical compliance* concerns of the Cautious group without diluting the *structural and safety* goals of the Supportive group."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12a714ed"
      },
      "source": [
        "# 6. Insights and Recommendations <a id=\"6-insights\"></a>\n",
        "\n",
        "**6.1 Summary of Key Findings**\n",
        "* **Stakeholder Polarization:** The inquiry is dominated by two primary blocs: Unions (advocating for safety/leave) and Industry Bodies (advocating for feasible compliance). Individual voices are marginal.\n",
        "* **Thematic Divergence:** While all groups discuss \"gender equality,\" they define it differently. Unions define it through **safety and rights** (Topic 4), Academics through **data and leadership** (Topic 3), and Industry through **legislation and schemes** (Topic 2).\n",
        "* **The \"Compliance\" Anxiety:** The strong clustering of \"Cautious\" submissions around Topic 2 suggests that resistance to the Bill is not ideological but administrative. Employers are worried about the *how*, not the *why*.\n",
        "\n",
        "**6.2 Recommendations for Policy Makers**\n",
        "\n",
        "Based on the text analysis, the following actions could bridge the gap between stakeholders:\n",
        "1.  **Clarify the \"Scheme\":** Since Topic 2 (Legislative Scheme) is the primary concern for Cautious stakeholders, the government should release detailed, plain-English guidance on compliance mechanics to reduce anxiety.\n",
        "2.  **Integrate Safety into Reporting:** Given the strong link between \"harassment\" and \"equality\" in Union submissions (Topic 4), the WGEA should consider making *workplace safety* a more explicit part of the reporting framework, moving beyond just pay gap metrics.\n",
        "3.  **Standardize Data Definitions:** The high frequency of \"data\" and \"methodology\" in Academic submissions (Topic 3) suggests a need for rigorous, standardized definitions of \"leadership\" and \"equity\" to ensure targets are measurable and comparable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8be30e95"
      },
      "source": [
        "# 7. Limitations and Next Steps <a id=\"7-limitations\"></a>\n",
        "\n",
        "**7.1 Limitations**\n",
        "* **Sample Size:** With only 31 submissions, the corpus is small. This limits the stability of the LDA model; adding or removing a single document could shift the topics slightly.\n",
        "* **Document Length Bias:** Despite TF-IDF normalization, longer submissions (e.g., from peak bodies) inherently contribute more tokens to the model than short individual letters, potentially drowning out grassroots voices.\n",
        "* **\"Stance\" Subjectivity:** The classification of submissions into \"Supportive\" vs. \"Cautious\" was done manually based on file names and initial reading. A more robust approach would use Sentiment Analysis scores to automate this classification.\n",
        "\n",
        "**7.2 Future Improvements**\n",
        "* **Sentiment Analysis:** Applying VADER or a Transformer-based sentiment model could quantify *how* positive or negative the language is within each topic (e.g., is the discussion of \"compliance\" fearful or constructive?).\n",
        "* **Longitudinal Analysis:** If this inquiry were recurring, tracking how these topics evolve over time (e.g., 2021 vs. 2024) would reveal if the debate is maturing or stagnating."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f9513c3"
      },
      "source": [
        "# 8. Conclusion <a id=\"8-conclusion\"></a>\n",
        "\n",
        "**8.1 Recap: The Story of the Data**\n",
        "\n",
        "This project applied Natural Language Processing (NLP) techniques to deconstruct the parliamentary discourse surrounding the *Workplace Gender Equality Amendment (Setting Gender Equality Targets) Bill 2024*. The analysis transformed an unstructured corpus of **31 PDF submissions** into a structured evidentiary base, revealing a landscape defined not by consensus, but by distinct, role-based vocabularies.\n",
        "\n",
        "The initial data inspection (Section 2) established a polarized consultation environment, evenly split between **Union/Worker Representatives** and **Industry/Employer Bodies**. Subsequent exploratory analysis (Section 4) demonstrated that while these groups ostensibly address the same legislation, they utilize fundamentally different lexicons. Unions prioritise the language of **\"safety,\" \"leave,\"** and **\"harassment,\"** while Industry bodies focus on **\"reporting,\" \"compliance,\"** and **\"schemes.\"**\n",
        "\n",
        "**8.2 Significance of Findings**\n",
        "\n",
        "The application of Latent Dirichlet Allocation (LDA) in Section 5 provided the most critical insight: the debate is compartmentalized into three parallel conversations.\n",
        "\n",
        "1. **The Compliance Conversation (Topic 2):** Dominated by \"Cautious\" stakeholders (67% prevalence), this discourse focuses on the mechanics of the law—review, scheme, policy.\n",
        "\n",
        "2. **The Structural Conversation (Topic 3):** Dominated by \"Supportive\" Advocacy groups, focusing on data, leadership, and evidence.\n",
        "\n",
        "3. **The Lived Experience Conversation (Topic 4):** Dominated by Unions, linking gender targets directly to health and violence prevention.\n",
        "\n",
        "These findings matter because they quantify the \"disconnect\" in the policy debate. The resistance to the Bill identified in \"Cautious\" submissions is rarely ideological; rather, the clustering results confirm it is deeply rooted in administrative anxiety regarding the legislative mechanism itself.\n",
        "\n",
        "**8.3 Interpretive Summary**\n",
        "\n",
        "The overarching research question asked how stakeholders frame the shift from voluntary reporting to mandatory targets. **The analysis leads to a definitive conclusion: The success of the Bill depends on bridging the gap between the \"Technical\" and the \"Human\" dimensions of gender equality.**\n",
        "\n",
        "The text analysis reveals a fundamental tension in the framing of the legislation. For **Employers**, the Bill is a regulatory instrument presenting compliance risk; their support is conditional on the clarity of the \"scheme\" (Topic 2). For **Workers and Advocates**, the Bill is a social instrument; their support is predicated on the targets delivering tangible safety and equity outcomes (Topic 4).\n",
        "\n",
        "Therefore, the data suggests that policy success will not be achieved by debating the *principle* of gender equality—on which there is broad lexical consensus—but by refining the *implementation* to satisfy the specific compliance definitions demanded by the Industry cluster.\n",
        "\n",
        "**8.4 Future Recommendations**\n",
        "\n",
        "Based on the limitations identified in this study (principally sample size and document length bias), future analysis should focus on:\n",
        "\n",
        "- **Sentiment Overlay:** Applying sentiment analysis to specific keywords like compliance and reporting to determine if Industry language expresses constructive caution or obstructionist negativity.\n",
        "- **Longitudinal Tracking:** Comparing these submissions to future inquiry data (post-implementation) to measure if the \"compliance anxiety\" (Topic 2) diminishes over time as the target setting becomes normalized."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCuiR4kZCp32"
      },
      "source": [
        "# 9. References <a id=\"9-references\"></a>\n",
        "\n",
        "1.  **Bird, S., Klein, E., & Loper, E.** (2009). *Natural Language Processing with Python*. O'Reilly Media.\n",
        "2.  **Blei, D. M., Ng, A. Y., & Jordan, M. I.** (2003). Latent Dirichlet Allocation. *Journal of Machine Learning Research*, 3, 993-1022.\n",
        "3.  **Parliament of Australia.** (2024). *Workplace Gender Equality Amendment (Setting Gender Equality Targets) Bill 2024*. Retrieved from [aph.gov.au](https://www.aph.gov.au)\n",
        "4.  **Workplace Gender Equality Agency (WGEA).** (2024). *Gender Equality Indicators*. Retrieved from [wgea.gov.au](https://www.wgea.gov.au)\n",
        "5.  **Pedregosa, F., et al.** (2011). Scikit-learn: Machine Learning in Python. *Journal of Machine Learning Research*, 12, 2825-2830."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "3.11.4",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0216609e7ecb4702b29fc8d6052b7bc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02c8f198976d49a4824ba1f943769023": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6083d51d358e4f9caaff7eb39de3cc80",
            "placeholder": "​",
            "style": "IPY_MODEL_b75957f7077f47eb985b806d2ab55d90",
            "value": "Processing Submissions: 100%"
          }
        },
        "19a4054507a040f9b32fd3bde5c3913c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2027e22ebcb5426fb03d97463dc373df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2beeba74bd8048869fc161b6df2cdf19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d900f7001010483fb76a6c5c612a2c36",
            "max": 31,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2027e22ebcb5426fb03d97463dc373df",
            "value": 31
          }
        },
        "2f123b12c83b48e184bac34507dc38bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_875fe2fde32f4cbe995edd5ef4b8e60b",
            "max": 31,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dae63b77cba545e28e8014dcad0e3c28",
            "value": 31
          }
        },
        "436311c4cc504ed0b75d9e9c60e16979": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4408f0ce670240efb7e6023e227c86e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52d227c31d224163b660d77bfdb78c05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77f78597e4bb42728e30c9e8eadec271",
            "placeholder": "​",
            "style": "IPY_MODEL_19a4054507a040f9b32fd3bde5c3913c",
            "value": " 31/31 [00:00&lt;00:00, 83.51it/s]"
          }
        },
        "57543cd80a7749888f3ed98be797446c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5933ae41cb614ed7811738a597e0e4d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5b3f681155d4b16b599f0c8b4ce2ca3",
              "IPY_MODEL_2beeba74bd8048869fc161b6df2cdf19",
              "IPY_MODEL_ac9b308419cf4208a95815fa50e6e956"
            ],
            "layout": "IPY_MODEL_632a6570f79f41e7aa8a7d9aa21c6db2"
          }
        },
        "6083d51d358e4f9caaff7eb39de3cc80": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "632a6570f79f41e7aa8a7d9aa21c6db2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "714101333be0494286303e138c5c5e37": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77f78597e4bb42728e30c9e8eadec271": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8071c0c04d8342a4b68b7827c16034f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ec67aea01d547008cf2b0209554154b",
              "IPY_MODEL_2f123b12c83b48e184bac34507dc38bf",
              "IPY_MODEL_52d227c31d224163b660d77bfdb78c05"
            ],
            "layout": "IPY_MODEL_4408f0ce670240efb7e6023e227c86e3"
          }
        },
        "8377408e7f99409a8ea5820f46293a62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84097da37bee40bbbee365f8248afb62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02c8f198976d49a4824ba1f943769023",
              "IPY_MODEL_e0eba986aedd4869a2cd8b652a376175",
              "IPY_MODEL_e7ec44fe4a364f348a419cf0c0e0e072"
            ],
            "layout": "IPY_MODEL_b7bd15568ef64f4cabe5efbc644674ab"
          }
        },
        "875fe2fde32f4cbe995edd5ef4b8e60b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ec67aea01d547008cf2b0209554154b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57543cd80a7749888f3ed98be797446c",
            "placeholder": "​",
            "style": "IPY_MODEL_8377408e7f99409a8ea5820f46293a62",
            "value": "Cleaning (No Stem): 100%"
          }
        },
        "8f76c307fa7c4272bb70c687323dcb91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5b3f681155d4b16b599f0c8b4ce2ca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_714101333be0494286303e138c5c5e37",
            "placeholder": "​",
            "style": "IPY_MODEL_0216609e7ecb4702b29fc8d6052b7bc4",
            "value": "Cleaning (Stemmed): 100%"
          }
        },
        "ac9b308419cf4208a95815fa50e6e956": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_436311c4cc504ed0b75d9e9c60e16979",
            "placeholder": "​",
            "style": "IPY_MODEL_8f76c307fa7c4272bb70c687323dcb91",
            "value": " 31/31 [00:00&lt;00:00, 28.89it/s]"
          }
        },
        "b75957f7077f47eb985b806d2ab55d90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7bd15568ef64f4cabe5efbc644674ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c85ccbd6df534ee58726b2af81edb591": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfa352a2031143d0a00b5ce268b7b03c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d900f7001010483fb76a6c5c612a2c36": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dae63b77cba545e28e8014dcad0e3c28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0eba986aedd4869a2cd8b652a376175": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c85ccbd6df534ee58726b2af81edb591",
            "max": 31,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5d869c5c6924118bbbd10088d4fd21e",
            "value": 31
          }
        },
        "e5d869c5c6924118bbbd10088d4fd21e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7ec44fe4a364f348a419cf0c0e0e072": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eeb4c46149d34fe38e6059b4bf81bf09",
            "placeholder": "​",
            "style": "IPY_MODEL_cfa352a2031143d0a00b5ce268b7b03c",
            "value": " 31/31 [02:12&lt;00:00,  3.26s/it]"
          }
        },
        "eeb4c46149d34fe38e6059b4bf81bf09": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
